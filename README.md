**Complete End To End Data Engineering Projectâ€Š-â€ŠSnowflake**
An end-to-end data engineering project using Snowflake typically involves fetching data from the source destination through an API or manually uploading the data files to the Snowflake staging, cleaning and preprocessing the unstructured data, and then ingesting it into raw tables and final usable tables.
This article is the one-stop place to understand the process from ingesting unstructured data into the snowflake staging location, to having a layered data architecture by de-duplicating, cleansing, and flattening JSON data to have analytics-ready data tables.
Source data and scripts can be found in the GitHub repository Data-Engineering-Project, you can clone the repository or download the resource files.

**ğŸ’ Technical Pre-requisites:**
Below are the pre-requisites required to complete this end-to-end Data Engineering project Snowflake
ğŸ”¹Snowflake Free Trial Edition:
ğŸ”¹Text Editor:
VS Code or Equivalent
ğŸ”¹JSON File Visualizer: (Optional)
Any free tool available on the internet.
ğŸ”¹Data Loading (CSV or JSON):
Snowsight data loading feature.
ğŸ”¹Realtime JSON Data Structure:
Govt free data
ğŸ”¹Data Source Consumption using API:
GitHub action


**â©Business Use CaseÂ :**
In this project, we will be looking into the Indian air quality data available here.
In the initial section, we will be ingesting the CSV data file that is already downloaded and available here, In the later part of the blog we will see how to consume the data through the API.
